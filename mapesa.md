STUDENT NAME: MARWA MAYENGO MAPESA
REG NO: 220242475481
BENG22COE 02
Assignment 0

QN 01.  During today's lecture, we saw data mining as one step in the knowledge discovery process. However, in industry, in media, and in the research environment, the term data mining is often used to describe the entire knowledge discovery process. Why is this the case?
 Introduction
What Is the Knowledge discovery Database (KDD)
Dating back to 1989, the namesake Knowledge Discovery in Database represents the overall process of collecting data and methodically refining it.
The KDD Process is a classic data science life cycle that aspires to purge the ‘noise’ (useless, tangential outliers) while establishing a phased approach to derive patterns and trends that add important knowledge.

According to the book of Heuristics and Optimization for Knowledge Discovery explain about the concept Data Mining (DM) and Knowledge Discovery in Databases (KDD) have been used interchangeably in practice. 
Definition of data mining:
Knowledge discovery in databases (KDD) is the process of extracting models and patterns from large databases. 
Or
Define the Knowledge discovery Database (KDD) process as: 
KDD is the process of model abstraction from large databases and searching for valid, novel, and nontrivial patterns and symptoms within the abstracted model.
The term data mining (DM) is often used as a synonym for the KDD process although strictly speaking it is just a step within KDD. 
DM refers to the process of applying the discovery algorithm to the data

What is the Data Mining Process?
Data mining is the process of extracting useful and previously unknown patterns from large datasets. It combines methods from artificial intelligence, machine learning, statistics, and database systems to discover hidden insights that can support better decision making. Although the term suggests just extracting data, the real focus is on uncovering valuable knowledge making "knowledge mining" a more accurate name. 
The following on which each step is defined is either in terms of time span or technical knowledge and human effort that Knowledge of Discovery in Data Mining. These steps are:
I.	Problem definition and determining the mining task, 
II.	Data description and selection, 
III.	Data conversion, 
IV.	Data cleaning, 
V.	Data transformation, 
VI.	Data reduction and projection, 
VII.	Domain-specific data preprocessing, 
VIII.	Feature selection, 
IX.	Choosing the mining algorithm, 
X.	Algorithm-specific data preprocessing, 
XI.	Applying the mining algorithm, 
XII.	Analyzing and refining the results, and 
XIII.	Knowledge consolidation.

The broader KDD process include the following listed bellow 
I.	KDD is a multi-step process that starts with raw data and ends with usable knowledge.
II.	Data selection: Identifying and gathering relevant data for the analysis.
III.	Data preprocessing: Cleaning and transforming the data into a suitable format for mining.
IV.	Data mining: Applying algorithms to find patterns in the prepared data.
V.	Pattern evaluation: Evaluating the discovered patterns to ensure they are meaningful and useful.
VI.	Knowledge presentation: Visualizing the results in a way that can be easily understood. 

Why the confusion occurs
•	Importance: Data mining is the most crucial and complex step of the KDD process, so it often gets the spotlight.
•	Simplification: It is a convenient shorthand to use "data mining" to represent the entire cycle of finding knowledge in data, especially in casual conversation or when the details of the other steps are less important to the discussion.

Conclusions
Knowledge discovery is a dialectic research process that is both deductive and inductive. Data mining is sometimes misconceived as “data-driven” or “fishing expedition” without theory guidance, contributing to a misunderstanding and hindrance in the social science research community i recognizing the contribution of this approach. While the relationship between theory and research differs between deductive and inductive research approaches, they complement each other. The two processes are often combined to form a cycle from theory to data and back to theory. Such a combination is not new in social science research, as Grounded Theory is a general method that uses systematic research to generate a theory that involves both inductive and deductive phases of research.

QN 02. What are the differences between data wrangling, scanning, and filtering in data mining?

1.	Data Wrangling:
Data Wrangling Also called Data Cleaning or Data Preparation it includes:
I.	Removing duplicates
II.	Handling missing values
III.	Correcting wrong data
IV.	Converting data types
V.	Combining multiple datasets
VI.	Normalizing / standardizing data
 Definition of Data Wrangling: is the process of transforming raw data into a usable, clean, and organized format before analysis.


2.	Data mining and data processing are distinct stages in the lifecycle of working with data. They overlap, but each has different goals, methods, and outputs. Below is a compact comparison and how they fit together.
I.	Data processing: transform raw data into a clean, consistent, usable form. Emphasis on correctness, formatting, aggregation, storage and basic calculation.
II.	Data mining: discover patterns, relationships, models, or actionable insights from processed data. Emphasis on exploration, pattern recognition, and predictive or descriptive modeling.
3.	Filtering in data mining is the process of refining raw data by selecting a relevant subset based on specific criteria, which removes errors, noise, and irrelevant information to improve accuracy and efficiency for analysis. It involves using rules or conditions to narrow down a dataset, allowing for more focused and manageable exploration, whether it's to isolate a particular time period, group of interest, or remove faulty data. 
